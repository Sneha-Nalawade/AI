{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JV_TGzReO3ou",
        "outputId": "aa6236fa-ae47-456a-a3e3-80bfdc7628bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WcIwqEcYVTO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import shutil\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc, accuracy_score\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "i9EJUqU8YvVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The folder is contained in this directory\n",
        "animal_dir = \"/content/drive/MyDrive/animals/animals\""
      ],
      "metadata": {
        "id": "V7Kbo8TRgKq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir(animal_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJN3zJoJgLGc",
        "outputId": "59359c1f-010e-457f-9c9d-b61385fe5af7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "90"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/name of the animals.txt\", 'r') as f:\n",
        "    animal_info = f.read()"
      ],
      "metadata": {
        "id": "8Jx9597pgMlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(animal_info.split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RX_F5gF1g5-N",
        "outputId": "3c08f55f-9bf4-4ffa-fe97-c7c327480317"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['antelope', 'badger', 'bat', 'bear', 'bee', 'beetle', 'bison', 'boar', 'butterfly', 'cat', 'caterpillar', 'chimpanzee', 'cockroach', 'cow', 'coyote', 'crab', 'crow', 'deer', 'dog', 'dolphin', 'donkey', 'dragonfly', 'duck', 'eagle', 'elephant', 'flamingo', 'fly', 'fox', 'goat', 'goldfish', 'goose', 'gorilla', 'grasshopper', 'hamster', 'hare', 'hedgehog', 'hippopotamus', 'hornbill', 'horse', 'hummingbird', 'hyena', 'jellyfish', 'kangaroo', 'koala', 'ladybugs', 'leopard', 'lion', 'lizard', 'lobster', 'mosquito', 'moth', 'mouse', 'octopus', 'okapi', 'orangutan', 'otter', 'owl', 'ox', 'oyster', 'panda', 'parrot', 'pelecaniformes', 'penguin', 'pig', 'pigeon', 'porcupine', 'possum', 'raccoon', 'rat', 'reindeer', 'rhinoceros', 'sandpiper', 'seahorse', 'seal', 'shark', 'sheep', 'snake', 'sparrow', 'squid', 'squirrel', 'starfish', 'swan', 'tiger', 'turkey', 'turtle', 'whale', 'wolf', 'wombat', 'woodpecker', 'zebra']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(animal_info.split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2RAGuW1g7ta",
        "outputId": "0e804117-debd-4315-da60-c9b5b9e7cb5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "90"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "animal_names = {}\n",
        "animal_directories = os.listdir(animal_dir)\n",
        "\n",
        "for animal_name in animal_directories:\n",
        "    animal_path = os.path.join(animal_dir, animal_name)\n",
        "    num_images = len(os.listdir(animal_path))\n",
        "    animal_names[animal_name] = num_images"
      ],
      "metadata": {
        "id": "qJLYPjUVg9jH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "animal_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-iiy7GKg_hu",
        "outputId": "708e747c-ab97-4b8a-81f3-e68bccada9f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'whale': 60,\n",
              " 'turtle': 60,\n",
              " 'woodpecker': 60,\n",
              " 'zebra': 60,\n",
              " 'swan': 60,\n",
              " 'tiger': 60,\n",
              " 'wolf': 60,\n",
              " 'turkey': 60,\n",
              " 'starfish': 60,\n",
              " 'wombat': 60,\n",
              " 'sandpiper': 60,\n",
              " 'squirrel': 60,\n",
              " 'sparrow': 60,\n",
              " 'shark': 60,\n",
              " 'seal': 60,\n",
              " 'squid': 60,\n",
              " 'snake': 60,\n",
              " 'rhinoceros': 60,\n",
              " 'seahorse': 60,\n",
              " 'sheep': 60,\n",
              " 'pig': 60,\n",
              " 'possum': 60,\n",
              " 'pelecaniformes': 60,\n",
              " 'penguin': 60,\n",
              " 'parrot': 60,\n",
              " 'raccoon': 60,\n",
              " 'porcupine': 60,\n",
              " 'pigeon': 60,\n",
              " 'rat': 60,\n",
              " 'reindeer': 60,\n",
              " 'orangutan': 60,\n",
              " 'moth': 60,\n",
              " 'owl': 60,\n",
              " 'okapi': 60,\n",
              " 'octopus': 60,\n",
              " 'oyster': 60,\n",
              " 'otter': 60,\n",
              " 'ox': 60,\n",
              " 'panda': 60,\n",
              " 'mouse': 60,\n",
              " 'lion': 60,\n",
              " 'hyena': 60,\n",
              " 'koala': 60,\n",
              " 'lizard': 60,\n",
              " 'lobster': 60,\n",
              " 'kangaroo': 60,\n",
              " 'leopard': 60,\n",
              " 'mosquito': 60,\n",
              " 'jellyfish': 60,\n",
              " 'ladybugs': 60,\n",
              " 'hippopotamus': 60,\n",
              " 'hamster': 60,\n",
              " 'gorilla': 60,\n",
              " 'grasshopper': 60,\n",
              " 'hare': 60,\n",
              " 'hornbill': 60,\n",
              " 'horse': 60,\n",
              " 'hedgehog': 60,\n",
              " 'goose': 60,\n",
              " 'hummingbird': 60,\n",
              " 'elephant': 60,\n",
              " 'duck': 60,\n",
              " 'goldfish': 60,\n",
              " 'flamingo': 60,\n",
              " 'dragonfly': 60,\n",
              " 'fly': 60,\n",
              " 'donkey': 60,\n",
              " 'goat': 60,\n",
              " 'eagle': 60,\n",
              " 'fox': 60,\n",
              " 'caterpillar': 60,\n",
              " 'crow': 60,\n",
              " 'dolphin': 60,\n",
              " 'cockroach': 60,\n",
              " 'cow': 60,\n",
              " 'crab': 60,\n",
              " 'deer': 60,\n",
              " 'chimpanzee': 60,\n",
              " 'coyote': 60,\n",
              " 'dog': 60,\n",
              " 'boar': 60,\n",
              " 'butterfly': 60,\n",
              " 'bear': 60,\n",
              " 'bee': 60,\n",
              " 'antelope': 60,\n",
              " 'bat': 60,\n",
              " 'beetle': 60,\n",
              " 'badger': 60,\n",
              " 'bison': 60,\n",
              " 'cat': 60}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/animals/animals/antelope/02f4b3be2d.jpg\"\n",
        "image = Image.open(image_path)\n",
        "width, height = image.size\n",
        "print(f\"width: {width}, height: {height}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTDErNB5hPy9",
        "outputId": "7854f4df-5893-44ec-8ed6-ad5f4cf51ae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "width: 1640, height: 1025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/animals/animals\""
      ],
      "metadata": {
        "id": "RuI-WN8miOYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class dataset_new(torch.utils.data.Dataset):\n",
        "    def __init__(self,data_idx,take=0.1,path=path):\n",
        "        super().__init__()\n",
        "        classes = os.listdir(path)\n",
        "        folder_name = classes[data_idx]\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "        self.transforms = transforms.Compose([\n",
        "            transforms.Resize(256), # 256 for efficient net , 224\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ])\n",
        "        for folder in classes:\n",
        "            if folder==folder_name:\n",
        "                limit = 1\n",
        "            else:\n",
        "                limit = take\n",
        "            anim_fold = os.path.join(path, folder)\n",
        "            for l,localpath in enumerate(os.listdir(anim_fold)):\n",
        "                if(l>=limit*len(os.listdir(anim_fold))):\n",
        "                    break\n",
        "                img_path = os.path.join(anim_fold, localpath)\n",
        "                self.images.append(img_path)\n",
        "                if folder==folder_name:\n",
        "                    self.labels.append(1)\n",
        "                else:\n",
        "                    self.labels.append(0)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    def __getitem__(self,idx):\n",
        "        img = Image.open(self.images[idx])\n",
        "        label = self.labels[idx]\n",
        "        return self.transforms(img), torch.tensor(label,dtype=torch.long)\n"
      ],
      "metadata": {
        "id": "Zc-MjqaJiSsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_label_classification_one_vs_rest_fold(model_net, name):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    name_model = str(name)\n",
        "    for i in range(90):\n",
        "        print(animal_info.split()[i])\n",
        "        dataset = dataset_new(i)\n",
        "\n",
        "        kfold = KFold(n_splits=3, shuffle=True)\n",
        "\n",
        "        print('--------------------------------')\n",
        "\n",
        "        for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
        "\n",
        "            print(f'FOLD {fold}')\n",
        "            print('--------------------------------')\n",
        "\n",
        "            train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
        "            test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
        "\n",
        "            train_loader = DataLoader(dataset, batch_size=32, sampler=train_subsampler, pin_memory=True, num_workers=2)\n",
        "            test_loader = DataLoader(dataset, batch_size=32, sampler=test_subsampler, pin_memory=True, num_workers=2)\n",
        "\n",
        "            model = model_net\n",
        "            model.to(device)\n",
        "\n",
        "            optimizer = optim.Adam(model.parameters(), lr=5e-5)\n",
        "            train_losses = []\n",
        "            test_losses = []\n",
        "            train_accuracies = []\n",
        "            test_accuracies = []\n",
        "\n",
        "            for epoch in range(3):\n",
        "\n",
        "                model.train()\n",
        "                correct = 0\n",
        "                total = 0\n",
        "                train_loss = 0.0\n",
        "                for _, (inputs, labels) in enumerate(train_loader):\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    outputs = model(inputs)\n",
        "                    loss = nn.CrossEntropyLoss()(outputs, labels)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    train_loss += loss.item()\n",
        "                    _, predicted = outputs.max(1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "                model.eval()\n",
        "                test_loss = 0.0\n",
        "                test_correct = 0\n",
        "                test_total = 0\n",
        "                all_labels = []\n",
        "                all_predictions = []\n",
        "\n",
        "                for inputs, labels in test_loader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    outputs = model(inputs)\n",
        "                    loss = nn.CrossEntropyLoss()(outputs, labels)\n",
        "                    test_loss += loss.item()*inputs.size(0)\n",
        "                    _, predicted = outputs.max(1)\n",
        "                    test_total += labels.size(0)\n",
        "                    test_correct += predicted.eq(labels).sum().item()\n",
        "                    all_labels.extend(labels.cpu().numpy())\n",
        "                    all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "                    test_loss = test_loss / len(test_loader)\n",
        "                    train_loss = train_loss/len(train_loader)\n",
        "                    test_accuracy = 100.0 * correct / total\n",
        "                    train_accuracy = 100.0 * test_correct/test_total\n",
        "\n",
        "                    train_losses.append(train_loss)\n",
        "                    test_losses.append(test_loss)\n",
        "                    train_accuracies.append(train_accuracy)\n",
        "                    test_accuracies.append(test_accuracy)\n",
        "\n",
        "                    print('Epoch: {} \\tTraining Loss: {:.6f} \\tTest Loss: {:.6f} \\tTrain Accuracy {:.6f}% \\tTest Accuracy: {:.2f}%'.format(\n",
        "                        epoch+1,\n",
        "                        train_loss,\n",
        "                        test_loss,\n",
        "                        train_accuracy,\n",
        "                        test_accuracy\n",
        "                        ))\n",
        "\n",
        "                    directory = f'/kaggle/working/one-vs-rest/{name}/{animal_info.split()[i]}/'\n",
        "                    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "                    plt.figure(figsize=(10, 5))\n",
        "                    plt.plot(train_accuracies, label='Train Accuracy')\n",
        "                    plt.plot(test_accuracies, label='Test Accuracy')\n",
        "                    plt.title('Accuracy Curve for Dataset Name: {} Fold {}'.format(animal_info.split()[i], fold))\n",
        "                    plt.xlabel('Epoch')\n",
        "                    plt.ylabel('Accuracy')\n",
        "                    plt.savefig(os.path.join(directory, f'{fold}.png'))\n",
        "\n",
        "\n",
        "                    print('Confusion Matrix for fold {}'.format(fold))\n",
        "                    print(confusion_matrix(all_labels, all_predictions))"
      ],
      "metadata": {
        "id": "3kech-U1iZWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpyW7-DVi5uA",
        "outputId": "5ae8ba7f-8712-4a96-be7e-843a98e85be5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet_pytorch) (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet_pytorch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet_pytorch) (1.3.0)\n",
            "Building wheels for collected packages: efficientnet_pytorch\n",
            "  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16428 sha256=a923803a6f0e0267fbcde94cb81015e4ce8ea93012b31d98c26e0daa47f8434d\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
            "Successfully built efficientnet_pytorch\n",
            "Installing collected packages: efficientnet_pytorch\n",
            "Successfully installed efficientnet_pytorch-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "class CEfficientNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b0')\n",
        "        self.fc = nn.Linear(1000, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.efficientnet(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "model_EfficientNet = CEfficientNet()\n",
        "run_label_classification_one_vs_rest_fold(model_EfficientNet, 'Effnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "T1flA-zgi8rW",
        "outputId": "b8d61064-a246-4c1e-baad-2d28bb752e90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'nn' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b7df11a901ed>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mefficientnet_pytorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEfficientNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mCEfficientNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "class CMobileNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.mobilenet = models.mobilenet_v2(pretrained=True)\n",
        "        self.fc = nn.Linear(1000, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.mobilenet(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "model_MobileNet = CMobileNet()\n",
        "run_label_classification_one_vs_rest_fold(model_MobileNet, 'Mobilenet')"
      ],
      "metadata": {
        "id": "ozJmpyOxjRo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, in_features):\n",
        "        super().__init__()\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(in_features, in_features),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(in_features, 1),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        attention_weights = self.attention(x)\n",
        "        return attention_weights * x\n",
        "\n",
        "class CustomCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(64*56*56, 1000)\n",
        "        self.attention = Attention(1000)\n",
        "        self.fc2 = nn.Linear(1000, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.attention(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model_CustomCNN = CustomCNN()\n",
        "run_label_classification_one_vs_rest_fold(model_CustomCNN, 'CustomCNN')"
      ],
      "metadata": {
        "id": "oU2yrICOjedT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/kaggle/input/animal-image-dataset-90-different-animals/animals/animals\""
      ],
      "metadata": {
        "id": "DsOgkiuJjsp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class dataset_pent_class(torch.utils.data.Dataset):\n",
        "    def __init__(self,start_idx, path=path, window_size= 5):\n",
        "        super().__init__()\n",
        "        classes = os.listdir(path)\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "        self.transforms = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ])\n",
        "        end_idx = start_idx*5 + window_size\n",
        "        for i in range(start_idx*5, end_idx):\n",
        "            folder_name = classes[i]\n",
        "            anim_fold = os.path.join(path, folder_name)\n",
        "            for localpath in os.listdir(anim_fold):\n",
        "                img_path = os.path.join(anim_fold, localpath)\n",
        "                self.images.append(img_path)\n",
        "                self.labels.append(i % window_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    def __getitem__(self,idx):\n",
        "        img = Image.open(self.images[idx])\n",
        "        label = self.labels[idx]\n",
        "        return self.transforms(img), torch.tensor(label, dtype=torch.long)"
      ],
      "metadata": {
        "id": "h2GxFhUojvA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_label_classification_one_vs_rest_fold(model_net, name, start_idx=0, window_size=5):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    name_model = str(name)\n",
        "    for i in range(start_idx, 17, window_size):\n",
        "        print(i, \"structure folder\")\n",
        "        dataset = dataset_pent_class(i, window_size=window_size)\n",
        "\n",
        "        kfold = KFold(n_splits=3, shuffle=True)\n",
        "\n",
        "        print('--------------------------------')\n",
        "\n",
        "        for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
        "\n",
        "            print(f'FOLD {fold}')\n",
        "            print('--------------------------------')\n",
        "\n",
        "            train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
        "            test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
        "\n",
        "            train_loader = DataLoader(dataset, batch_size=32, sampler=train_subsampler, pin_memory=True, num_workers=2)\n",
        "            test_loader = DataLoader(dataset, batch_size=32, sampler=test_subsampler, pin_memory=True, num_workers=2)\n",
        "\n",
        "            model = model_net\n",
        "            model.to(device)\n",
        "\n",
        "            optimizer = optim.Adam(model.parameters(), lr=5e-5)\n",
        "            train_losses = []\n",
        "            test_losses = []\n",
        "            train_accuracies = []\n",
        "            test_accuracies = []\n",
        "\n",
        "            for epoch in range(3):\n",
        "\n",
        "                model.train()\n",
        "                correct = 0\n",
        "                total = 0\n",
        "                train_loss = 0.0\n",
        "                for _, (inputs, labels) in enumerate(train_loader):\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    outputs = model(inputs)\n",
        "                    loss = nn.CrossEntropyLoss()(outputs, labels)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    train_loss += loss.item()\n",
        "                    _, predicted = outputs.max(1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "                model.eval()\n",
        "                test_loss = 0.0\n",
        "                test_correct = 0\n",
        "                test_total = 0\n",
        "                all_labels = []\n",
        "                all_predictions = []\n",
        "\n",
        "                for inputs, labels in test_loader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    outputs = model(inputs)\n",
        "                    loss = nn.CrossEntropyLoss()(outputs, labels)\n",
        "                    test_loss += loss.item()*inputs.size(0)\n",
        "                    _, predicted = outputs.max(1)\n",
        "                    test_total += labels.size(0)\n",
        "                    test_correct += predicted.eq(labels).sum().item()\n",
        "                    all_labels.extend(labels.cpu().numpy())\n",
        "                    all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "\n",
        "                test_loss = test_loss / len(test_loader)\n",
        "                train_loss = train_loss/len(train_loader)\n",
        "                test_accuracy = 100.0 * correct / total\n",
        "                train_accuracy = 100.0 * test_correct/test_total\n",
        "\n",
        "                train_losses.append(train_loss)\n",
        "                test_losses.append(test_loss)\n",
        "                train_accuracies.append(train_accuracy)\n",
        "                test_accuracies.append(test_accuracy)\n",
        "\n",
        "                print('Epoch: {} \\tTraining Loss: {:.6f} \\tTest Loss: {:.6f} \\tTrain Accuracy {:.6f}% \\tTest Accuracy: {:.2f}%'.format(\n",
        "                    epoch+1,\n",
        "                    train_loss,\n",
        "                    test_loss,\n",
        "                    train_accuracy,\n",
        "                    test_accuracy\n",
        "                    ))\n",
        "\n",
        "            directory = f'/kaggle/working/5fold/{i}/{fold}/'\n",
        "            os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "            plt.figure(figsize=(10, 5))\n",
        "            plt.plot(train_accuracies, label='Train Accuracy')\n",
        "            plt.plot(test_accuracies, label='Test Accuracy')\n",
        "            plt.title('Accuracy Curve for {} Dataset, Fold {}'.format(i, fold))\n",
        "            plt.xlabel('Epoch')\n",
        "            plt.ylabel('Accuracy')\n",
        "            plt.savefig(os.path.join(directory, f'{fold}.png'))\n",
        "\n",
        "            model_directory = f'/kaggle/working/5fold_model/'\n",
        "            os.makedirs(model_directory, exist_ok=True)\n",
        "            torch.save(model.state_dict(), os.path.join(model_directory, f'{name_model}.pth'))\n",
        "\n",
        "\n",
        "            print('Confusion Matrix for fold {}'.format(fold))\n",
        "            print(confusion_matrix(all_labels, all_predictions))\n",
        "\n"
      ],
      "metadata": {
        "id": "kSU_CNPLj13G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet_pytorch"
      ],
      "metadata": {
        "id": "ahhLWd14_mxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "class CEfficientNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b0')\n",
        "        self.fc = nn.Linear(1000, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.efficientnet(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "model_EfficientNet = CEfficientNet()\n",
        "run_label_classification_one_vs_rest_fold(model_EfficientNet, 'EffNet', 0, 5)"
      ],
      "metadata": {
        "id": "-cIoUG4I_phS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "class CMobileNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.mobilenet = models.mobilenet_v2(pretrained=True)\n",
        "        self.fc = nn.Linear(1000, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.mobilenet(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "model_MobileNet = CMobileNet()\n",
        "run_label_classification_one_vs_rest_fold(model_MobileNet, 'MobileNet', 0, 5)"
      ],
      "metadata": {
        "id": "LmkeLJo__zhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, in_features):\n",
        "        super().__init__()\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(in_features, in_features),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(in_features, 1),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        attention_weights = self.attention(x)\n",
        "        return attention_weights * x\n",
        "\n",
        "class CustomCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(64*56*56, 1000)\n",
        "        self.attention = Attention(1000)\n",
        "        self.fc2 = nn.Linear(1000, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.attention(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model_CustomCNN = CustomCNN()\n",
        "run_label_classification_one_vs_rest_fold(model_CustomCNN, 'CustomCNN', 0, 5)"
      ],
      "metadata": {
        "id": "pQGp5cCf_5Gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision import models, transforms, utils\n",
        "from torch.autograd import Variable\n",
        "import scipy.misc\n",
        "import json"
      ],
      "metadata": {
        "id": "sU7yTWJ6AFKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "8bmNeArOAHFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Taking an Image\n",
        "image = Image.open(str('/kaggle/input/animal-image-dataset-90-different-animals/animals/animals/antelope/02f4b3be2d.jpg'))\n",
        "plt.imshow(image)"
      ],
      "metadata": {
        "id": "jVPis_rNAJCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transforms = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "\n",
        "def nn_layer_visual(image, model, model_path):\n",
        "\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "\n",
        "        model_weights =[]\n",
        "        conv_layers = []\n",
        "        model_children = list(model.children())\n",
        "        counter = 0\n",
        "        for i in range(len(model_children)):\n",
        "            if type(model_children[i]) == nn.Conv2d:\n",
        "                counter+=1\n",
        "                model_weights.append(model_children[i].weight)\n",
        "                conv_layers.append(model_children[i])\n",
        "            elif type(model_children[i]) == nn.Sequential:\n",
        "                for j in range(len(model_children[i])):\n",
        "                    for child in model_children[i][j].children():\n",
        "                        if type(child) == nn.Conv2d:\n",
        "                            counter+=1\n",
        "                            model_weights.append(child.weight)\n",
        "                            conv_layers.append(child)\n",
        "        print(f\"Total convolution layers: {counter}\")\n",
        "        print(\"conv_layers\")\n",
        "\n",
        "        image = transforms(image)\n",
        "        print(f\"Image shape before: {image.shape}\")\n",
        "        image = image.unsqueeze(0)\n",
        "        print(f\"Image shape after: {image.shape}\")\n",
        "\n",
        "        if len(image.shape) == 3:\n",
        "            image = image.unsqueeze(0)\n",
        "\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        image = image.to(device)\n",
        "\n",
        "        print(f\"Image shape before: {image.shape}\")\n",
        "\n",
        "        outputs = []\n",
        "        names = []\n",
        "        for layer in conv_layers[0:]:\n",
        "            image = layer(image)\n",
        "            outputs.append(image)\n",
        "            names.append(str(layer))\n",
        "\n",
        "        print(len(outputs))\n",
        "        for feature_map in outputs:\n",
        "            print(feature_map.shape)\n",
        "\n",
        "        processed = []\n",
        "        for feature_map in outputs:\n",
        "            feature_map = feature_map.squeeze(0)\n",
        "            gray_scale = torch.sum(feature_map,0)\n",
        "            gray_scale = gray_scale / feature_map.shape[0]\n",
        "            processed.append(gray_scale.data.cpu().numpy())\n",
        "        for fm in processed:\n",
        "            print(fm.shape)\n",
        "\n",
        "        fig = plt.figure(figsize=(30, 50))\n",
        "        for i in range(len(processed)):\n",
        "            a = fig.add_subplot(5, 4, i+1)\n",
        "            imgplot = plt.imshow(processed[i])\n",
        "            a.axis(\"off\")\n",
        "            a.set_title(names[i].split('(')[0], fontsize=30)\n",
        "\n"
      ],
      "metadata": {
        "id": "d1bWCz5MALVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn_layer_visual(image, model_CustomCNN, '/kaggle/working/5fold_model/CustomCNN.pth')"
      ],
      "metadata": {
        "id": "X3bcwC97AcEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5kKdOryMOb34"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}